{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "np.random.seed(123)  # for reproducibility\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D, Conv2D, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import binary_accuracy, categorical_accuracy, binary_crossentropy, categorical_crossentropy\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6235012 , 1.69270833, 3.25814536, 1.03668262, 0.71507151,\n",
       "       1.12262522, 0.90845563, 0.6372549 , 1.20705664, 0.63076177,\n",
       "       0.74328188, 0.93390805, 0.390039  , 2.24525043, 7.22222222,\n",
       "       0.91036415, 3.49462366, 0.83493899, 0.86493679, 0.88255261,\n",
       "       1.25240848, 1.96969697, 0.90845563, 0.65162907, 1.27077224,\n",
       "       2.29276896, 0.53630363, 2.92792793, 2.35507246, 1.07526882])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_MAP = {'antelope': 0,\n",
    " 'bat': 1,\n",
    " 'beaver': 2,\n",
    " 'bobcat': 3,\n",
    " 'buffalo': 4,\n",
    " 'chihuahua': 5,\n",
    " 'chimpanzee': 6,\n",
    " 'collie': 7,\n",
    " 'dalmatian': 8,\n",
    " 'german+shepherd': 9,\n",
    " 'grizzly+bear': 10,\n",
    " 'hippopotamus': 11,\n",
    " 'horse': 12,\n",
    " 'killer+whale': 13,\n",
    " 'mole': 14,\n",
    " 'moose': 15,\n",
    " 'mouse': 16,\n",
    " 'otter': 17,\n",
    " 'ox': 18,\n",
    " 'persian+cat': 19,\n",
    " 'raccoon': 20,\n",
    " 'rat': 21,\n",
    " 'rhinoceros': 22,\n",
    " 'seal': 23,\n",
    " 'siamese+cat': 24,\n",
    " 'spider+monkey': 25,\n",
    " 'squirrel': 26,\n",
    " 'walrus': 27,\n",
    " 'weasel': 28,\n",
    " 'wolf': 29}\n",
    "# CLASS_WEIGHTS = {0: 0.0017985611510791368,\n",
    "#  1: 0.004878048780487805,\n",
    "#  2: 0.009345794392523364,\n",
    "#  3: 0.0029850746268656717,\n",
    "#  4: 0.002061855670103093,\n",
    "#  5: 0.003236245954692557,\n",
    "#  6: 0.002617801047120419,\n",
    "#  7: 0.001838235294117647,\n",
    "#  8: 0.003472222222222222,\n",
    "#  9: 0.0018181818181818182,\n",
    "#  10: 0.0021413276231263384,\n",
    "#  11: 0.002688172043010753,\n",
    "#  12: 0.0011248593925759281,\n",
    "#  13: 0.0064516129032258064,\n",
    "#  14: 0.020833333333333332,\n",
    "#  15: 0.0026246719160104987,\n",
    "#  16: 0.01,\n",
    "#  17: 0.002403846153846154,\n",
    "#  18: 0.0024937655860349127,\n",
    "#  19: 0.002544529262086514,\n",
    "#  20: 0.0036101083032490976,\n",
    "#  21: 0.005681818181818182,\n",
    "#  22: 0.002617801047120419,\n",
    "#  23: 0.0018796992481203006,\n",
    "#  24: 0.003663003663003663,\n",
    "#  25: 0.006578947368421052,\n",
    "#  26: 0.0015455950540958269,\n",
    "#  27: 0.008403361344537815,\n",
    "#  28: 0.006756756756756757,\n",
    "#  29: 0.0030959752321981426}\n",
    "CLASS_WEIGHTS = compute_class_weight('balanced', np.arange(0, 30), target.argmax(axis=1))\n",
    "CLASS_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13000, 2048), (13000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"extracted/train_resnet_feat.csv\", index_col=\"Image_id\")\n",
    "target = train[\"target\"]\n",
    "train = train.drop(\"target\", axis=1).values\n",
    "target = target.map(CLASS_MAP).values\n",
    "train.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'acc' not in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'acc' not in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    for ll, vl in zip(loss_list, val_loss_list):\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, history.history[ll], 'b', label=f'{ll} ({history.history[ll][-1]:.5f})')\n",
    "        plt.plot(epochs, history.history[vl], 'g', label=f'{vl} ({history.history[vl][-1]:.5f})')\n",
    "    \n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    for ll, vl in zip(acc_list, val_acc_list):\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, history.history[ll], 'b', label=f'{ll} ({history.history[ll][-1]:.5f})')\n",
    "        plt.plot(epochs, history.history[vl], 'g', label=f'{vl} ({history.history[vl][-1]:.5f})')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = to_categorical(target)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(2048,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "#     opt = 'adam'\n",
    "    opt = SGD(lr=0.0003, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[categorical_accuracy])\n",
    "    return model\n",
    "def fit_model(model, train, target, val_data, val_target, epochs, batch_size=32, verbose=2):\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                  patience=2, min_lr=0.0000001, verbose=1)\n",
    "    early_stops = EarlyStopping(monitor='val_loss',\n",
    "                    patience=15, verbose=1,)\n",
    "    \n",
    "    history = model.fit(train, target,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(val_data, val_target),\n",
    "          class_weight=CLASS_WEIGHTS, \n",
    "            callbacks=[reduce_lr, early_stops],\n",
    "            verbose=verbose)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1/5...\n",
      "Train on 10387 samples, validate on 2613 samples\n",
      "Epoch 1/30\n",
      "10387/10387 [==============================] - 7s 646us/step - loss: 1.6739 - categorical_accuracy: 0.5793 - val_loss: 0.7319 - val_categorical_accuracy: 0.8171\n",
      "Epoch 2/30\n",
      "10387/10387 [==============================] - 6s 592us/step - loss: 0.7332 - categorical_accuracy: 0.8122 - val_loss: 0.5594 - val_categorical_accuracy: 0.8565\n",
      "Epoch 3/30\n",
      "10387/10387 [==============================] - 6s 594us/step - loss: 0.5639 - categorical_accuracy: 0.8595 - val_loss: 0.4896 - val_categorical_accuracy: 0.8718\n",
      "Epoch 4/30\n",
      "10387/10387 [==============================] - 6s 600us/step - loss: 0.4685 - categorical_accuracy: 0.8815 - val_loss: 0.4426 - val_categorical_accuracy: 0.8848\n",
      "Epoch 5/30\n",
      "10387/10387 [==============================] - 6s 614us/step - loss: 0.4074 - categorical_accuracy: 0.8968 - val_loss: 0.4160 - val_categorical_accuracy: 0.8909\n",
      "Epoch 6/30\n",
      "10387/10387 [==============================] - 6s 609us/step - loss: 0.3609 - categorical_accuracy: 0.9087 - val_loss: 0.3955 - val_categorical_accuracy: 0.8936\n",
      "Epoch 7/30\n",
      "10387/10387 [==============================] - 6s 615us/step - loss: 0.3225 - categorical_accuracy: 0.9212 - val_loss: 0.3794 - val_categorical_accuracy: 0.8974\n",
      "Epoch 8/30\n",
      "10387/10387 [==============================] - 6s 620us/step - loss: 0.2896 - categorical_accuracy: 0.9276 - val_loss: 0.3682 - val_categorical_accuracy: 0.8951\n",
      "Epoch 9/30\n",
      "10387/10387 [==============================] - 6s 618us/step - loss: 0.2708 - categorical_accuracy: 0.9348 - val_loss: 0.3609 - val_categorical_accuracy: 0.8990\n",
      "Epoch 10/30\n",
      "10387/10387 [==============================] - 6s 624us/step - loss: 0.2470 - categorical_accuracy: 0.9397 - val_loss: 0.3514 - val_categorical_accuracy: 0.9005\n",
      "Epoch 11/30\n",
      "10387/10387 [==============================] - 7s 642us/step - loss: 0.2318 - categorical_accuracy: 0.9430 - val_loss: 0.3447 - val_categorical_accuracy: 0.9043\n",
      "Epoch 12/30\n",
      "10387/10387 [==============================] - 6s 612us/step - loss: 0.2115 - categorical_accuracy: 0.9522 - val_loss: 0.3401 - val_categorical_accuracy: 0.9028\n",
      "Epoch 13/30\n",
      "10387/10387 [==============================] - 6s 612us/step - loss: 0.1988 - categorical_accuracy: 0.9542 - val_loss: 0.3336 - val_categorical_accuracy: 0.9039\n",
      "Epoch 14/30\n",
      "10387/10387 [==============================] - 6s 615us/step - loss: 0.1818 - categorical_accuracy: 0.9592 - val_loss: 0.3319 - val_categorical_accuracy: 0.9024\n",
      "Epoch 15/30\n",
      "10387/10387 [==============================] - 6s 621us/step - loss: 0.1684 - categorical_accuracy: 0.9654 - val_loss: 0.3303 - val_categorical_accuracy: 0.9036\n",
      "Epoch 16/30\n",
      "10387/10387 [==============================] - 7s 627us/step - loss: 0.1602 - categorical_accuracy: 0.9672 - val_loss: 0.3259 - val_categorical_accuracy: 0.9039\n",
      "Epoch 17/30\n",
      "10387/10387 [==============================] - 6s 609us/step - loss: 0.1511 - categorical_accuracy: 0.9689 - val_loss: 0.3226 - val_categorical_accuracy: 0.9047\n",
      "Epoch 18/30\n",
      "10387/10387 [==============================] - 6s 611us/step - loss: 0.1444 - categorical_accuracy: 0.9703 - val_loss: 0.3213 - val_categorical_accuracy: 0.9062\n",
      "Epoch 19/30\n",
      "10387/10387 [==============================] - 6s 613us/step - loss: 0.1318 - categorical_accuracy: 0.9755 - val_loss: 0.3220 - val_categorical_accuracy: 0.9047\n",
      "Epoch 20/30\n",
      "10387/10387 [==============================] - 6s 612us/step - loss: 0.1294 - categorical_accuracy: 0.9745 - val_loss: 0.3186 - val_categorical_accuracy: 0.9055\n",
      "Epoch 21/30\n",
      "10387/10387 [==============================] - 6s 619us/step - loss: 0.1219 - categorical_accuracy: 0.9757 - val_loss: 0.3180 - val_categorical_accuracy: 0.9055\n",
      "Epoch 22/30\n",
      "10387/10387 [==============================] - 6s 621us/step - loss: 0.1122 - categorical_accuracy: 0.9805 - val_loss: 0.3171 - val_categorical_accuracy: 0.9070\n",
      "Epoch 23/30\n",
      "10387/10387 [==============================] - 6s 615us/step - loss: 0.1102 - categorical_accuracy: 0.9802 - val_loss: 0.3155 - val_categorical_accuracy: 0.9059\n",
      "Epoch 24/30\n",
      "10387/10387 [==============================] - 6s 621us/step - loss: 0.1000 - categorical_accuracy: 0.9821 - val_loss: 0.3140 - val_categorical_accuracy: 0.9062\n",
      "Epoch 25/30\n",
      "10387/10387 [==============================] - 6s 614us/step - loss: 0.0953 - categorical_accuracy: 0.9840 - val_loss: 0.3125 - val_categorical_accuracy: 0.9074\n",
      "Epoch 26/30\n",
      "10387/10387 [==============================] - 6s 622us/step - loss: 0.0924 - categorical_accuracy: 0.9846 - val_loss: 0.3121 - val_categorical_accuracy: 0.9074\n",
      "Epoch 27/30\n",
      "10387/10387 [==============================] - 6s 622us/step - loss: 0.0900 - categorical_accuracy: 0.9848 - val_loss: 0.3123 - val_categorical_accuracy: 0.9078\n",
      "Epoch 28/30\n",
      "10387/10387 [==============================] - 6s 621us/step - loss: 0.0853 - categorical_accuracy: 0.9865 - val_loss: 0.3103 - val_categorical_accuracy: 0.9093\n",
      "Epoch 29/30\n",
      "10387/10387 [==============================] - 7s 628us/step - loss: 0.0808 - categorical_accuracy: 0.9876 - val_loss: 0.3097 - val_categorical_accuracy: 0.9101\n",
      "Epoch 30/30\n",
      "10387/10387 [==============================] - 7s 626us/step - loss: 0.0751 - categorical_accuracy: 0.9899 - val_loss: 0.3095 - val_categorical_accuracy: 0.9074\n",
      "FOLD 2/5...\n",
      "Train on 10396 samples, validate on 2604 samples\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 7s 682us/step - loss: 1.6512 - categorical_accuracy: 0.5878 - val_loss: 0.7615 - val_categorical_accuracy: 0.8061\n",
      "Epoch 2/30\n",
      " 5312/10396 [==============>...............] - ETA: 3s - loss: 0.7623 - categorical_accuracy: 0.8089"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8dfb4437801b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestdex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestdex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mkfold_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-55ca8d20e0c7>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, train, target, val_data, val_target, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLASS_WEIGHTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold_history = []\n",
    "for it, (traindex, testdex) in enumerate(k_folds.split(train, target.argmax(axis=1))):\n",
    "    print(f\"FOLD {it+1}/{k_folds.get_n_splits()}...\")\n",
    "    model = load_model()\n",
    "    history = fit_model(model, train[traindex], target[traindex], \n",
    "                        train[testdex], target[testdex], \n",
    "                        epochs=epochs, batch_size=batch_size, \n",
    "                        verbose=1)\n",
    "    kfold_history.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "losses = []\n",
    "for hist in kfold_history:\n",
    "    val_losses.append(hist.history['val_loss'][-1])\n",
    "    losses.append(hist.history['loss'][-1])\n",
    "print(\"BatchNorm with SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) [30 epochs]\")\n",
    "print(f\"Average validation loss:   {np.mean(val_losses):.4f} + {np.std(val_losses):.4f}\")\n",
    "print(f\"Average training loss: {np.mean(losses):.4f} + {np.mean(losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm with SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) [30 epochs]\n",
      "Average validation loss:   0.3080 + 0.0000\n",
      "Average training loss: 0.0889 + 0.0889\n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "losses = []\n",
    "for hist in kfold_history:\n",
    "    val_losses.append(hist.history['val_loss'][-1])\n",
    "    losses.append(hist.history['loss'][-1])\n",
    "print(\"BatchNorm with SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True) [30 epochs]\")\n",
    "print(f\"Average validation loss:   {np.mean(val_losses):.4f} + {np.std(val_losses):.4f}\")\n",
    "print(f\"Average training loss: {np.mean(losses):.4f} + {np.mean(losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10400 samples, validate on 2600 samples\n",
      "Epoch 1/100\n",
      "10400/10400 [==============================] - 5s 439us/step - loss: 2.3247 - categorical_accuracy: 0.4078 - val_loss: 1.0472 - val_categorical_accuracy: 0.7319\n",
      "Epoch 2/100\n",
      "10400/10400 [==============================] - 4s 380us/step - loss: 1.0799 - categorical_accuracy: 0.7223 - val_loss: 0.7582 - val_categorical_accuracy: 0.8073\n",
      "Epoch 3/100\n",
      "10400/10400 [==============================] - 4s 383us/step - loss: 0.8162 - categorical_accuracy: 0.7884 - val_loss: 0.6421 - val_categorical_accuracy: 0.8358\n",
      "Epoch 4/100\n",
      "10400/10400 [==============================] - 4s 385us/step - loss: 0.6910 - categorical_accuracy: 0.8171 - val_loss: 0.5772 - val_categorical_accuracy: 0.8492\n",
      "Epoch 5/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.6082 - categorical_accuracy: 0.8441 - val_loss: 0.5313 - val_categorical_accuracy: 0.8608\n",
      "Epoch 6/100\n",
      "10400/10400 [==============================] - 4s 384us/step - loss: 0.5414 - categorical_accuracy: 0.8611 - val_loss: 0.4985 - val_categorical_accuracy: 0.8681\n",
      "Epoch 7/100\n",
      "10400/10400 [==============================] - 4s 384us/step - loss: 0.5039 - categorical_accuracy: 0.8673 - val_loss: 0.4725 - val_categorical_accuracy: 0.8765\n",
      "Epoch 8/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.4594 - categorical_accuracy: 0.8798 - val_loss: 0.4541 - val_categorical_accuracy: 0.8792\n",
      "Epoch 9/100\n",
      "10400/10400 [==============================] - 4s 384us/step - loss: 0.4320 - categorical_accuracy: 0.8850 - val_loss: 0.4384 - val_categorical_accuracy: 0.8835\n",
      "Epoch 10/100\n",
      "10400/10400 [==============================] - 4s 384us/step - loss: 0.4108 - categorical_accuracy: 0.8913 - val_loss: 0.4258 - val_categorical_accuracy: 0.8892\n",
      "Epoch 11/100\n",
      "10400/10400 [==============================] - 4s 385us/step - loss: 0.3853 - categorical_accuracy: 0.8995 - val_loss: 0.4165 - val_categorical_accuracy: 0.8927\n",
      "Epoch 12/100\n",
      "10400/10400 [==============================] - 4s 387us/step - loss: 0.3640 - categorical_accuracy: 0.9057 - val_loss: 0.4073 - val_categorical_accuracy: 0.8904\n",
      "Epoch 13/100\n",
      "10400/10400 [==============================] - 4s 386us/step - loss: 0.3488 - categorical_accuracy: 0.9077 - val_loss: 0.3988 - val_categorical_accuracy: 0.8927\n",
      "Epoch 14/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.3333 - categorical_accuracy: 0.9155 - val_loss: 0.3912 - val_categorical_accuracy: 0.8946\n",
      "Epoch 15/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.3135 - categorical_accuracy: 0.9180 - val_loss: 0.3846 - val_categorical_accuracy: 0.8946\n",
      "Epoch 16/100\n",
      "10400/10400 [==============================] - 4s 390us/step - loss: 0.2960 - categorical_accuracy: 0.9249 - val_loss: 0.3795 - val_categorical_accuracy: 0.8962\n",
      "Epoch 17/100\n",
      "10400/10400 [==============================] - 4s 386us/step - loss: 0.2878 - categorical_accuracy: 0.9272 - val_loss: 0.3730 - val_categorical_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.2737 - categorical_accuracy: 0.9314 - val_loss: 0.3696 - val_categorical_accuracy: 0.8992\n",
      "Epoch 19/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.2626 - categorical_accuracy: 0.9332 - val_loss: 0.3645 - val_categorical_accuracy: 0.9008\n",
      "Epoch 20/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.2589 - categorical_accuracy: 0.9345 - val_loss: 0.3619 - val_categorical_accuracy: 0.8996\n",
      "Epoch 21/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.2467 - categorical_accuracy: 0.9365 - val_loss: 0.3594 - val_categorical_accuracy: 0.9015\n",
      "Epoch 22/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.2360 - categorical_accuracy: 0.9404 - val_loss: 0.3559 - val_categorical_accuracy: 0.9015\n",
      "Epoch 23/100\n",
      "10400/10400 [==============================] - 4s 388us/step - loss: 0.2267 - categorical_accuracy: 0.9421 - val_loss: 0.3524 - val_categorical_accuracy: 0.9019\n",
      "Epoch 24/100\n",
      "10400/10400 [==============================] - 4s 394us/step - loss: 0.2224 - categorical_accuracy: 0.9417 - val_loss: 0.3496 - val_categorical_accuracy: 0.9019\n",
      "Epoch 25/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.2130 - categorical_accuracy: 0.9493 - val_loss: 0.3473 - val_categorical_accuracy: 0.9008\n",
      "Epoch 26/100\n",
      "10400/10400 [==============================] - 4s 396us/step - loss: 0.2081 - categorical_accuracy: 0.9480 - val_loss: 0.3467 - val_categorical_accuracy: 0.9019\n",
      "Epoch 27/100\n",
      "10400/10400 [==============================] - 4s 396us/step - loss: 0.1953 - categorical_accuracy: 0.9530 - val_loss: 0.3439 - val_categorical_accuracy: 0.9031\n",
      "Epoch 28/100\n",
      "10400/10400 [==============================] - 4s 388us/step - loss: 0.1888 - categorical_accuracy: 0.9552 - val_loss: 0.3408 - val_categorical_accuracy: 0.9031\n",
      "Epoch 29/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.1864 - categorical_accuracy: 0.9566 - val_loss: 0.3398 - val_categorical_accuracy: 0.9035\n",
      "Epoch 30/100\n",
      "10400/10400 [==============================] - 4s 402us/step - loss: 0.1811 - categorical_accuracy: 0.9567 - val_loss: 0.3389 - val_categorical_accuracy: 0.9019\n",
      "Epoch 31/100\n",
      "10400/10400 [==============================] - 4s 390us/step - loss: 0.1780 - categorical_accuracy: 0.9567 - val_loss: 0.3374 - val_categorical_accuracy: 0.9019\n",
      "Epoch 32/100\n",
      "10400/10400 [==============================] - 4s 390us/step - loss: 0.1731 - categorical_accuracy: 0.9573 - val_loss: 0.3374 - val_categorical_accuracy: 0.9019\n",
      "Epoch 33/100\n",
      "10400/10400 [==============================] - 4s 395us/step - loss: 0.1645 - categorical_accuracy: 0.9607 - val_loss: 0.3351 - val_categorical_accuracy: 0.9023\n",
      "Epoch 34/100\n",
      "10400/10400 [==============================] - 4s 396us/step - loss: 0.1629 - categorical_accuracy: 0.9628 - val_loss: 0.3335 - val_categorical_accuracy: 0.9023\n",
      "Epoch 35/100\n",
      "10400/10400 [==============================] - 4s 396us/step - loss: 0.1531 - categorical_accuracy: 0.9655 - val_loss: 0.3316 - val_categorical_accuracy: 0.9023\n",
      "Epoch 36/100\n",
      "10400/10400 [==============================] - 4s 420us/step - loss: 0.1495 - categorical_accuracy: 0.9661 - val_loss: 0.3309 - val_categorical_accuracy: 0.9027\n",
      "Epoch 37/100\n",
      "10400/10400 [==============================] - 4s 388us/step - loss: 0.1456 - categorical_accuracy: 0.9681 - val_loss: 0.3304 - val_categorical_accuracy: 0.9042\n",
      "Epoch 38/100\n",
      "10400/10400 [==============================] - 4s 389us/step - loss: 0.1433 - categorical_accuracy: 0.9674 - val_loss: 0.3307 - val_categorical_accuracy: 0.9046\n",
      "Epoch 39/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.1393 - categorical_accuracy: 0.9706 - val_loss: 0.3294 - val_categorical_accuracy: 0.9058\n",
      "Epoch 40/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.1349 - categorical_accuracy: 0.9711 - val_loss: 0.3292 - val_categorical_accuracy: 0.9046\n",
      "Epoch 41/100\n",
      "10400/10400 [==============================] - 4s 399us/step - loss: 0.1312 - categorical_accuracy: 0.9719 - val_loss: 0.3269 - val_categorical_accuracy: 0.9050\n",
      "Epoch 42/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.1255 - categorical_accuracy: 0.9729 - val_loss: 0.3267 - val_categorical_accuracy: 0.9054\n",
      "Epoch 43/100\n",
      "10400/10400 [==============================] - 4s 402us/step - loss: 0.1205 - categorical_accuracy: 0.9734 - val_loss: 0.3248 - val_categorical_accuracy: 0.9058\n",
      "Epoch 44/100\n",
      "10400/10400 [==============================] - 4s 398us/step - loss: 0.1198 - categorical_accuracy: 0.9760 - val_loss: 0.3254 - val_categorical_accuracy: 0.9062\n",
      "Epoch 45/100\n",
      "10400/10400 [==============================] - 4s 399us/step - loss: 0.1186 - categorical_accuracy: 0.9765 - val_loss: 0.3250 - val_categorical_accuracy: 0.9065\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 46/100\n",
      "10400/10400 [==============================] - 4s 400us/step - loss: 0.1155 - categorical_accuracy: 0.9768 - val_loss: 0.3244 - val_categorical_accuracy: 0.9058\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.1139 - categorical_accuracy: 0.9776 - val_loss: 0.3243 - val_categorical_accuracy: 0.9054\n",
      "Epoch 48/100\n",
      "10400/10400 [==============================] - 4s 389us/step - loss: 0.1137 - categorical_accuracy: 0.9760 - val_loss: 0.3241 - val_categorical_accuracy: 0.9062\n",
      "Epoch 49/100\n",
      "10400/10400 [==============================] - 4s 390us/step - loss: 0.1138 - categorical_accuracy: 0.9773 - val_loss: 0.3238 - val_categorical_accuracy: 0.9065\n",
      "Epoch 50/100\n",
      "10400/10400 [==============================] - 4s 386us/step - loss: 0.1100 - categorical_accuracy: 0.9811 - val_loss: 0.3240 - val_categorical_accuracy: 0.9062\n",
      "Epoch 51/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.1134 - categorical_accuracy: 0.9756 - val_loss: 0.3241 - val_categorical_accuracy: 0.9062\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 52/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.1099 - categorical_accuracy: 0.9778 - val_loss: 0.3238 - val_categorical_accuracy: 0.9062\n",
      "Epoch 53/100\n",
      "10400/10400 [==============================] - 4s 392us/step - loss: 0.1082 - categorical_accuracy: 0.9806 - val_loss: 0.3236 - val_categorical_accuracy: 0.9065\n",
      "Epoch 54/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.1097 - categorical_accuracy: 0.9774 - val_loss: 0.3235 - val_categorical_accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "10400/10400 [==============================] - 4s 394us/step - loss: 0.1095 - categorical_accuracy: 0.9795 - val_loss: 0.3235 - val_categorical_accuracy: 0.9062\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 56/100\n",
      "10400/10400 [==============================] - 4s 395us/step - loss: 0.1060 - categorical_accuracy: 0.9790 - val_loss: 0.3234 - val_categorical_accuracy: 0.9062\n",
      "Epoch 57/100\n",
      "10400/10400 [==============================] - 4s 387us/step - loss: 0.1033 - categorical_accuracy: 0.9796 - val_loss: 0.3234 - val_categorical_accuracy: 0.9062\n",
      "Epoch 58/100\n",
      "10400/10400 [==============================] - 4s 399us/step - loss: 0.1096 - categorical_accuracy: 0.9793 - val_loss: 0.3237 - val_categorical_accuracy: 0.9062\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 59/100\n",
      "10400/10400 [==============================] - 4s 397us/step - loss: 0.1048 - categorical_accuracy: 0.9798 - val_loss: 0.3236 - val_categorical_accuracy: 0.9058\n",
      "Epoch 60/100\n",
      "10400/10400 [==============================] - 4s 389us/step - loss: 0.1100 - categorical_accuracy: 0.9775 - val_loss: 0.3230 - val_categorical_accuracy: 0.9062\n",
      "Epoch 61/100\n",
      "10400/10400 [==============================] - 4s 397us/step - loss: 0.1062 - categorical_accuracy: 0.9800 - val_loss: 0.3233 - val_categorical_accuracy: 0.9069\n",
      "Epoch 62/100\n",
      "10400/10400 [==============================] - 4s 396us/step - loss: 0.1067 - categorical_accuracy: 0.9803 - val_loss: 0.3233 - val_categorical_accuracy: 0.9069\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "Epoch 63/100\n",
      "10400/10400 [==============================] - 4s 397us/step - loss: 0.1094 - categorical_accuracy: 0.9775 - val_loss: 0.3234 - val_categorical_accuracy: 0.9062\n",
      "Epoch 64/100\n",
      "10400/10400 [==============================] - 4s 390us/step - loss: 0.1065 - categorical_accuracy: 0.9797 - val_loss: 0.3235 - val_categorical_accuracy: 0.9069\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "Epoch 65/100\n",
      "10400/10400 [==============================] - 4s 397us/step - loss: 0.1048 - categorical_accuracy: 0.9807 - val_loss: 0.3233 - val_categorical_accuracy: 0.9065\n",
      "Epoch 66/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.1082 - categorical_accuracy: 0.9802 - val_loss: 0.3236 - val_categorical_accuracy: 0.9058\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 67/100\n",
      "10400/10400 [==============================] - 4s 395us/step - loss: 0.1046 - categorical_accuracy: 0.9806 - val_loss: 0.3234 - val_categorical_accuracy: 0.9062\n",
      "Epoch 68/100\n",
      "10400/10400 [==============================] - 4s 395us/step - loss: 0.1090 - categorical_accuracy: 0.9793 - val_loss: 0.3234 - val_categorical_accuracy: 0.9065\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 69/100\n",
      "10400/10400 [==============================] - 4s 399us/step - loss: 0.1035 - categorical_accuracy: 0.9807 - val_loss: 0.3234 - val_categorical_accuracy: 0.9062\n",
      "Epoch 70/100\n",
      "10400/10400 [==============================] - 4s 391us/step - loss: 0.1038 - categorical_accuracy: 0.9811 - val_loss: 0.3233 - val_categorical_accuracy: 0.9065\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 71/100\n",
      "10400/10400 [==============================] - 4s 394us/step - loss: 0.1082 - categorical_accuracy: 0.9793 - val_loss: 0.3232 - val_categorical_accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "10400/10400 [==============================] - 4s 397us/step - loss: 0.1044 - categorical_accuracy: 0.9788 - val_loss: 0.3233 - val_categorical_accuracy: 0.9058\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 73/100\n",
      "10400/10400 [==============================] - 4s 401us/step - loss: 0.1072 - categorical_accuracy: 0.9771 - val_loss: 0.3234 - val_categorical_accuracy: 0.9058\n",
      "Epoch 74/100\n",
      "10400/10400 [==============================] - 4s 395us/step - loss: 0.1068 - categorical_accuracy: 0.9793 - val_loss: 0.3236 - val_categorical_accuracy: 0.9065\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 75/100\n",
      "10400/10400 [==============================] - 4s 393us/step - loss: 0.1080 - categorical_accuracy: 0.9784 - val_loss: 0.3235 - val_categorical_accuracy: 0.9062\n",
      "Epoch 00075: early stopping\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                  patience=2, min_lr=0.0000001, verbose=1)\n",
    "early_stops = EarlyStopping(monitor='val_loss',\n",
    "                patience=15, verbose=1,)\n",
    "epochs = 25\n",
    "batch_size = 60\n",
    "model = load_model()\n",
    "history = model.fit(train, target,\n",
    "          epochs=100,\n",
    "          batch_size=batch_size,\n",
    "          class_weight=CLASS_WEIGHTS, validation_split=0.2,\n",
    "            callbacks=[reduce_lr, early_stops],\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_model_weights_path = 'MODEL/top_model_initial.h5'\n",
    "model.save_weights(top_model_weights_path)\n",
    "with open(\"MODEL/top_model_initial.json\", \"w\") as fp:\n",
    "    fp.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MODEL/ResNet/top_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
