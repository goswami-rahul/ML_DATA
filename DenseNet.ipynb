{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential, load_model, model_from_json, Model\n",
    "from keras.applications.densenet import preprocess_input, DenseNet201\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import MaxPooling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "# run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAP = {'antelope': 0,\n",
    " 'bat': 1,\n",
    " 'beaver': 2,\n",
    " 'bobcat': 3,\n",
    " 'buffalo': 4,\n",
    " 'chihuahua': 5,\n",
    " 'chimpanzee': 6,\n",
    " 'collie': 7,\n",
    " 'dalmatian': 8,\n",
    " 'german+shepherd': 9,\n",
    " 'grizzly+bear': 10,\n",
    " 'hippopotamus': 11,\n",
    " 'horse': 12,\n",
    " 'killer+whale': 13,\n",
    " 'mole': 14,\n",
    " 'moose': 15,\n",
    " 'mouse': 16,\n",
    " 'otter': 17,\n",
    " 'ox': 18,\n",
    " 'persian+cat': 19,\n",
    " 'raccoon': 20,\n",
    " 'rat': 21,\n",
    " 'rhinoceros': 22,\n",
    " 'seal': 23,\n",
    " 'siamese+cat': 24,\n",
    " 'spider+monkey': 25,\n",
    " 'squirrel': 26,\n",
    " 'walrus': 27,\n",
    " 'weasel': 28,\n",
    " 'wolf': 29}\n",
    "CLASS_WEIGHTS = [0.6235012 , 1.69270833, 3.25814536, 1.03668262, 0.71507151,\n",
    "       1.12262522, 0.90845563, 0.6372549 , 1.20705664, 0.63076177,\n",
    "       0.74328188, 0.93390805, 0.390039  , 2.24525043, 7.22222222,\n",
    "       0.91036415, 3.49462366, 0.83493899, 0.86493679, 0.88255261,\n",
    "       1.25240848, 1.96969697, 0.90845563, 0.65162907, 1.27077224,\n",
    "       2.29276896, 0.53630363, 2.92792793, 2.35507246, 1.07526882]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10412 images belonging to 30 classes.\n",
      "Found 2588 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "resol = 224\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input,\n",
    "        )\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data/',  # this is the target directory\n",
    "        target_size=(resol, resol),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') \n",
    "\n",
    "\n",
    "# # this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'test_data/',\n",
    "        target_size=(resol, resol),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_top_model_densenet():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(1920,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet201(include_top=False, pooling='avg')\n",
    "top = load_top_model_densenet()\n",
    "\n",
    "x = top(base_model.outputs)\n",
    "model = Model(inputs=base_model.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finetuning 0 hidden layers\n",
      "Epoch 1/20\n",
      "650/650 [==============================] - 907s 1s/step - loss: 0.7134 - categorical_accuracy: 0.8078 - val_loss: 0.4157 - val_categorical_accuracy: 0.8762\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41566, saving model to checkpoints/DenseNet/weights_unfreezed_0.01-0.42.hdf5\n",
      "Epoch 2/20\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.5706 - categorical_accuracy: 0.8397 - val_loss: 0.3757 - val_categorical_accuracy: 0.8828\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41566 to 0.37574, saving model to checkpoints/DenseNet/weights_unfreezed_0.02-0.38.hdf5\n",
      "Epoch 3/20\n",
      "650/650 [==============================] - 888s 1s/step - loss: 0.5157 - categorical_accuracy: 0.8546 - val_loss: 0.3385 - val_categorical_accuracy: 0.8948\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37574 to 0.33850, saving model to checkpoints/DenseNet/weights_unfreezed_0.03-0.34.hdf5\n",
      "Epoch 4/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.4679 - categorical_accuracy: 0.8714 - val_loss: 0.3203 - val_categorical_accuracy: 0.9045\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33850 to 0.32034, saving model to checkpoints/DenseNet/weights_unfreezed_0.04-0.32.hdf5\n",
      "Epoch 5/20\n",
      "650/650 [==============================] - 882s 1s/step - loss: 0.4282 - categorical_accuracy: 0.8779 - val_loss: 0.2979 - val_categorical_accuracy: 0.9030\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32034 to 0.29793, saving model to checkpoints/DenseNet/weights_unfreezed_0.05-0.30.hdf5\n",
      "Epoch 6/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.4020 - categorical_accuracy: 0.8833 - val_loss: 0.3093 - val_categorical_accuracy: 0.9030\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29793\n",
      "Epoch 7/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3796 - categorical_accuracy: 0.8908 - val_loss: 0.2934 - val_categorical_accuracy: 0.9068\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.29793 to 0.29345, saving model to checkpoints/DenseNet/weights_unfreezed_0.07-0.29.hdf5\n",
      "Epoch 8/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3748 - categorical_accuracy: 0.8907 - val_loss: 0.2879 - val_categorical_accuracy: 0.9107\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29345 to 0.28791, saving model to checkpoints/DenseNet/weights_unfreezed_0.08-0.29.hdf5\n",
      "Epoch 9/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3427 - categorical_accuracy: 0.8986 - val_loss: 0.2745 - val_categorical_accuracy: 0.9134\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28791 to 0.27446, saving model to checkpoints/DenseNet/weights_unfreezed_0.09-0.27.hdf5\n",
      "Epoch 10/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3451 - categorical_accuracy: 0.8976 - val_loss: 0.2634 - val_categorical_accuracy: 0.9165\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.27446 to 0.26344, saving model to checkpoints/DenseNet/weights_unfreezed_0.10-0.26.hdf5\n",
      "Epoch 11/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3258 - categorical_accuracy: 0.9034 - val_loss: 0.2597 - val_categorical_accuracy: 0.9161\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.26344 to 0.25966, saving model to checkpoints/DenseNet/weights_unfreezed_0.11-0.26.hdf5\n",
      "Epoch 12/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.3050 - categorical_accuracy: 0.9111 - val_loss: 0.2662 - val_categorical_accuracy: 0.9154\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.25966\n",
      "Epoch 13/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.2988 - categorical_accuracy: 0.9131 - val_loss: 0.2548 - val_categorical_accuracy: 0.9216\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.25966 to 0.25478, saving model to checkpoints/DenseNet/weights_unfreezed_0.13-0.25.hdf5\n",
      "Epoch 14/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.2864 - categorical_accuracy: 0.9142 - val_loss: 0.2521 - val_categorical_accuracy: 0.9227\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25478 to 0.25206, saving model to checkpoints/DenseNet/weights_unfreezed_0.14-0.25.hdf5\n",
      "Epoch 15/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.2972 - categorical_accuracy: 0.9097 - val_loss: 0.2568 - val_categorical_accuracy: 0.9173\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.25206\n",
      "Epoch 16/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.2649 - categorical_accuracy: 0.9192 - val_loss: 0.2575 - val_categorical_accuracy: 0.9185\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25206\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 17/20\n",
      "650/650 [==============================] - 883s 1s/step - loss: 0.2621 - categorical_accuracy: 0.9217 - val_loss: 0.2579 - val_categorical_accuracy: 0.9185\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.25206\n",
      "Epoch 18/20\n",
      "650/650 [==============================] - 882s 1s/step - loss: 0.2508 - categorical_accuracy: 0.9265 - val_loss: 0.2480 - val_categorical_accuracy: 0.9212\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.25206 to 0.24796, saving model to checkpoints/DenseNet/weights_unfreezed_0.18-0.25.hdf5\n",
      "Epoch 19/20\n",
      "650/650 [==============================] - 882s 1s/step - loss: 0.2471 - categorical_accuracy: 0.9268 - val_loss: 0.2513 - val_categorical_accuracy: 0.9220\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24796\n",
      "Epoch 20/20\n",
      "650/650 [==============================] - 882s 1s/step - loss: 0.2440 - categorical_accuracy: 0.9271 - val_loss: 0.2494 - val_categorical_accuracy: 0.9196\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24796\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "\n",
      "Finetuning 5 hidden layers\n",
      "Epoch 1/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2453 - categorical_accuracy: 0.9249 - val_loss: 0.2232 - val_categorical_accuracy: 0.9290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22316, saving model to checkpoints/DenseNet/weights_unfreezed_5.01-0.22.hdf5\n",
      "Epoch 2/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2522 - categorical_accuracy: 0.9267 - val_loss: 0.2180 - val_categorical_accuracy: 0.9290\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22316 to 0.21800, saving model to checkpoints/DenseNet/weights_unfreezed_5.02-0.22.hdf5\n",
      "Epoch 3/10\n",
      "650/650 [==============================] - 886s 1s/step - loss: 0.2483 - categorical_accuracy: 0.9246 - val_loss: 0.2172 - val_categorical_accuracy: 0.9286\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21800 to 0.21724, saving model to checkpoints/DenseNet/weights_unfreezed_5.03-0.22.hdf5\n",
      "Epoch 4/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2387 - categorical_accuracy: 0.9314 - val_loss: 0.2142 - val_categorical_accuracy: 0.9309\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21724 to 0.21421, saving model to checkpoints/DenseNet/weights_unfreezed_5.04-0.21.hdf5\n",
      "Epoch 5/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2444 - categorical_accuracy: 0.9272 - val_loss: 0.2195 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21421\n",
      "Epoch 6/10\n",
      "650/650 [==============================] - 886s 1s/step - loss: 0.2375 - categorical_accuracy: 0.9277 - val_loss: 0.2206 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21421\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 7/10\n",
      "650/650 [==============================] - 886s 1s/step - loss: 0.2376 - categorical_accuracy: 0.9295 - val_loss: 0.2212 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21421\n",
      "Epoch 8/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2276 - categorical_accuracy: 0.9317 - val_loss: 0.2192 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21421\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "Epoch 9/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2479 - categorical_accuracy: 0.9265 - val_loss: 0.2169 - val_categorical_accuracy: 0.9282\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21421\n",
      "Epoch 10/10\n",
      "650/650 [==============================] - 887s 1s/step - loss: 0.2368 - categorical_accuracy: 0.9289 - val_loss: 0.2141 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21421 to 0.21412, saving model to checkpoints/DenseNet/weights_unfreezed_5.10-0.21.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "\n",
      "Finetuning 10 hidden layers\n",
      "Epoch 1/10\n",
      "650/650 [==============================] - 904s 1s/step - loss: 0.2321 - categorical_accuracy: 0.9329 - val_loss: 0.2171 - val_categorical_accuracy: 0.9321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21712, saving model to checkpoints/DenseNet/weights_unfreezed_10.01-0.22.hdf5\n",
      "Epoch 2/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2382 - categorical_accuracy: 0.9285 - val_loss: 0.2166 - val_categorical_accuracy: 0.9274\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21712 to 0.21659, saving model to checkpoints/DenseNet/weights_unfreezed_10.02-0.22.hdf5\n",
      "Epoch 3/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2340 - categorical_accuracy: 0.9270 - val_loss: 0.2160 - val_categorical_accuracy: 0.9290\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21659 to 0.21599, saving model to checkpoints/DenseNet/weights_unfreezed_10.03-0.22.hdf5\n",
      "Epoch 4/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2251 - categorical_accuracy: 0.9344 - val_loss: 0.2157 - val_categorical_accuracy: 0.9290\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21599 to 0.21565, saving model to checkpoints/DenseNet/weights_unfreezed_10.04-0.22.hdf5\n",
      "Epoch 5/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2345 - categorical_accuracy: 0.9310 - val_loss: 0.2163 - val_categorical_accuracy: 0.9293\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21565\n",
      "Epoch 6/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2156 - categorical_accuracy: 0.9380 - val_loss: 0.2189 - val_categorical_accuracy: 0.9305\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21565\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 7/10\n",
      "650/650 [==============================] - 891s 1s/step - loss: 0.2253 - categorical_accuracy: 0.9337 - val_loss: 0.2163 - val_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21565\n",
      "Epoch 8/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2241 - categorical_accuracy: 0.9324 - val_loss: 0.2160 - val_categorical_accuracy: 0.9325\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21565\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "Epoch 9/10\n",
      "650/650 [==============================] - 892s 1s/step - loss: 0.2241 - categorical_accuracy: 0.9335 - val_loss: 0.2146 - val_categorical_accuracy: 0.9325\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21565 to 0.21459, saving model to checkpoints/DenseNet/weights_unfreezed_10.09-0.21.hdf5\n",
      "Epoch 10/10\n",
      "650/650 [==============================] - 891s 1s/step - loss: 0.2280 - categorical_accuracy: 0.9316 - val_loss: 0.2143 - val_categorical_accuracy: 0.9309\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21459 to 0.21428, saving model to checkpoints/DenseNet/weights_unfreezed_10.10-0.21.hdf5\n",
      "\n",
      "Finetuning 15 hidden layers\n",
      "Epoch 1/10\n",
      "650/650 [==============================] - 906s 1s/step - loss: 0.2221 - categorical_accuracy: 0.9312 - val_loss: 0.2165 - val_categorical_accuracy: 0.9328\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21647, saving model to checkpoints/DenseNet/weights_unfreezed_15.01-0.22.hdf5\n",
      "Epoch 2/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2153 - categorical_accuracy: 0.9348 - val_loss: 0.2100 - val_categorical_accuracy: 0.9328\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21647 to 0.21000, saving model to checkpoints/DenseNet/weights_unfreezed_15.02-0.21.hdf5\n",
      "Epoch 3/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2225 - categorical_accuracy: 0.9357 - val_loss: 0.2074 - val_categorical_accuracy: 0.9328\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21000 to 0.20743, saving model to checkpoints/DenseNet/weights_unfreezed_15.03-0.21.hdf5\n",
      "Epoch 4/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2069 - categorical_accuracy: 0.9344 - val_loss: 0.2109 - val_categorical_accuracy: 0.9344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20743\n",
      "Epoch 5/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2152 - categorical_accuracy: 0.9351 - val_loss: 0.2071 - val_categorical_accuracy: 0.9356\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20743 to 0.20708, saving model to checkpoints/DenseNet/weights_unfreezed_15.05-0.21.hdf5\n",
      "Epoch 6/10\n",
      "650/650 [==============================] - 897s 1s/step - loss: 0.2132 - categorical_accuracy: 0.9377 - val_loss: 0.2073 - val_categorical_accuracy: 0.9344\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20708\n",
      "Epoch 7/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.1977 - categorical_accuracy: 0.9389 - val_loss: 0.2073 - val_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20708\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 8/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.1934 - categorical_accuracy: 0.9419 - val_loss: 0.2092 - val_categorical_accuracy: 0.9348\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20708\n",
      "Epoch 9/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.1889 - categorical_accuracy: 0.9424 - val_loss: 0.2099 - val_categorical_accuracy: 0.9356\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20708\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "Epoch 10/10\n",
      "650/650 [==============================] - 896s 1s/step - loss: 0.2029 - categorical_accuracy: 0.9383 - val_loss: 0.2075 - val_categorical_accuracy: 0.9328\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20708\n",
      "\n",
      "Finetuning 20 hidden layers\n",
      "Epoch 1/10\n",
      "650/650 [==============================] - 914s 1s/step - loss: 0.1967 - categorical_accuracy: 0.9404 - val_loss: 0.2167 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21674, saving model to checkpoints/DenseNet/weights_unfreezed_20.01-0.22.hdf5\n",
      "Epoch 2/10\n",
      "650/650 [==============================] - 901s 1s/step - loss: 0.2068 - categorical_accuracy: 0.9360 - val_loss: 0.2082 - val_categorical_accuracy: 0.9348\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21674 to 0.20825, saving model to checkpoints/DenseNet/weights_unfreezed_20.02-0.21.hdf5\n",
      "Epoch 3/10\n",
      "650/650 [==============================] - 901s 1s/step - loss: 0.2002 - categorical_accuracy: 0.9403 - val_loss: 0.2089 - val_categorical_accuracy: 0.9356\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20825\n",
      "Epoch 4/10\n",
      "650/650 [==============================] - 902s 1s/step - loss: 0.1988 - categorical_accuracy: 0.9392 - val_loss: 0.2091 - val_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20825\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 5/10\n",
      "650/650 [==============================] - 902s 1s/step - loss: 0.1912 - categorical_accuracy: 0.9424 - val_loss: 0.2015 - val_categorical_accuracy: 0.9371\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20825 to 0.20149, saving model to checkpoints/DenseNet/weights_unfreezed_20.05-0.20.hdf5\n",
      "Epoch 6/10\n",
      "650/650 [==============================] - 902s 1s/step - loss: 0.1979 - categorical_accuracy: 0.9401 - val_loss: 0.2068 - val_categorical_accuracy: 0.9317\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20149\n",
      "Epoch 7/10\n",
      "650/650 [==============================] - 901s 1s/step - loss: 0.1865 - categorical_accuracy: 0.9427 - val_loss: 0.2071 - val_categorical_accuracy: 0.9348\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20149\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "Epoch 8/10\n",
      "650/650 [==============================] - 901s 1s/step - loss: 0.1683 - categorical_accuracy: 0.9497 - val_loss: 0.2086 - val_categorical_accuracy: 0.9356\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20149\n",
      "Epoch 9/10\n",
      "650/650 [==============================] - 902s 1s/step - loss: 0.1821 - categorical_accuracy: 0.9472 - val_loss: 0.2074 - val_categorical_accuracy: 0.9332\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20149\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "Epoch 10/10\n",
      "650/650 [==============================] - 901s 1s/step - loss: 0.1922 - categorical_accuracy: 0.9411 - val_loss: 0.2064 - val_categorical_accuracy: 0.9332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20149\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0003, 0.0001, 0.0001, 0.0001, 0.0001]\n",
    "epoch_list = [20, 10, 10, 10, 10]\n",
    "for rnd in range(5):\n",
    "    n_layers = rnd * 5\n",
    "    if n_layers > 0:\n",
    "        for layer in base_model.layers[-n_layers:]:\n",
    "            layer.trainable = True\n",
    "    n_trainable = sum(m.trainable for m in base_model.layers)\n",
    "    print(f\"\\nFinetuning {n_trainable} hidden layers\")\n",
    "    \n",
    "    opt = SGD(lr=lr_list[rnd], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[categorical_accuracy])\n",
    "    \n",
    "    path = f\"checkpoints/DenseNet/weights_unfreezed_{n_trainable}.\"\n",
    "    model_checkpointer = ModelCheckpoint(filepath=path+\"{epoch:02d}-{val_loss:.2f}.hdf5\", \n",
    "                                        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                  patience=2, min_lr=0.0000001, verbose=1)\n",
    "    early_stops = EarlyStopping(monitor='val_loss',\n",
    "                    patience=15, verbose=1,)\n",
    "    \n",
    "    my_callbacks = []\n",
    "    my_callbacks.append(model_checkpointer)\n",
    "    my_callbacks.append(reduce_lr)\n",
    "    my_callbacks.append(early_stops)\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=10412 // batch_size, # 10412\n",
    "            epochs=epoch_list[rnd],\n",
    "            verbose=1,\n",
    "            callbacks=my_callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=2588 // batch_size, # 2588\n",
    "            class_weight=CLASS_WEIGHTS,\n",
    "            )\n",
    "    pd.DataFrame(history.history).to_csv(f\"RESULTS/DenseNet/history_unfreezed_{n_trainable}.csv\")\n",
    "    model.save(f'MODEL/DenseNet/densenet_unfreezed_{n_trainable}.h5') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "import gc\n",
    "def load_top_model_resnet():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(2048,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10412 images belonging to 30 classes.\n",
      "Found 2588 images belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "resol = 224\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input,\n",
    "        )\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train_data/',  # this is the target directory\n",
    "        target_size=(resol, resol),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') \n",
    "\n",
    "\n",
    "# # this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'test_data/',\n",
    "        target_size=(resol, resol),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118037"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = ResNet50(include_top=False, pooling='avg')\n",
    "top = load_top_model_resnet()\n",
    "\n",
    "x = top(base_model.outputs)\n",
    "model = Model(inputs=base_model.inputs, outputs=x)\n",
    "del top \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finetuning 0 hidden layers\n",
      "Epoch 1/20\n",
      "650/650 [==============================] - 574s 883ms/step - loss: 0.4273 - categorical_accuracy: 0.8730 - val_loss: 0.3996 - val_categorical_accuracy: 0.8781\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39958, saving model to checkpoints/ResNet/weights_unfreezed_0.01-0.40.hdf5\n",
      "Epoch 2/20\n",
      "650/650 [==============================] - 587s 904ms/step - loss: 0.4269 - categorical_accuracy: 0.8729 - val_loss: 0.3823 - val_categorical_accuracy: 0.8808\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39958 to 0.38230, saving model to checkpoints/ResNet/weights_unfreezed_0.02-0.38.hdf5\n",
      "Epoch 3/20\n",
      "650/650 [==============================] - 589s 906ms/step - loss: 0.4115 - categorical_accuracy: 0.8756 - val_loss: 0.3768 - val_categorical_accuracy: 0.8781\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38230 to 0.37682, saving model to checkpoints/ResNet/weights_unfreezed_0.03-0.38.hdf5\n",
      "Epoch 4/20\n",
      "650/650 [==============================] - 621s 956ms/step - loss: 0.4018 - categorical_accuracy: 0.8782 - val_loss: 0.3945 - val_categorical_accuracy: 0.8754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37682\n",
      "Epoch 5/20\n",
      "650/650 [==============================] - 609s 936ms/step - loss: 0.3920 - categorical_accuracy: 0.8825 - val_loss: 0.3879 - val_categorical_accuracy: 0.8793\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37682\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 6/20\n",
      "650/650 [==============================] - 603s 928ms/step - loss: 0.3771 - categorical_accuracy: 0.8889 - val_loss: 0.3815 - val_categorical_accuracy: 0.8808\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37682\n",
      "Epoch 7/20\n",
      "650/650 [==============================] - 596s 917ms/step - loss: 0.3817 - categorical_accuracy: 0.8836 - val_loss: 0.3745 - val_categorical_accuracy: 0.8859\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.37682 to 0.37446, saving model to checkpoints/ResNet/weights_unfreezed_0.07-0.37.hdf5\n",
      "Epoch 8/20\n",
      "650/650 [==============================] - 654s 1s/step - loss: 0.3680 - categorical_accuracy: 0.8857 - val_loss: 0.3778 - val_categorical_accuracy: 0.8855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37446\n",
      "Epoch 9/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3702 - categorical_accuracy: 0.8870 - val_loss: 0.3801 - val_categorical_accuracy: 0.8797\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37446\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 10/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3578 - categorical_accuracy: 0.8914 - val_loss: 0.3684 - val_categorical_accuracy: 0.8855\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37446 to 0.36836, saving model to checkpoints/ResNet/weights_unfreezed_0.10-0.37.hdf5\n",
      "Epoch 11/20\n",
      "650/650 [==============================] - 585s 901ms/step - loss: 0.3496 - categorical_accuracy: 0.8948 - val_loss: 0.3682 - val_categorical_accuracy: 0.8847\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36836 to 0.36816, saving model to checkpoints/ResNet/weights_unfreezed_0.11-0.37.hdf5\n",
      "Epoch 12/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3470 - categorical_accuracy: 0.8943 - val_loss: 0.3774 - val_categorical_accuracy: 0.8832\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36816\n",
      "Epoch 13/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3554 - categorical_accuracy: 0.8885 - val_loss: 0.3734 - val_categorical_accuracy: 0.8851\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36816\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 14/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3528 - categorical_accuracy: 0.8931 - val_loss: 0.3665 - val_categorical_accuracy: 0.8804\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.36816 to 0.36654, saving model to checkpoints/ResNet/weights_unfreezed_0.14-0.37.hdf5\n",
      "Epoch 15/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3560 - categorical_accuracy: 0.8904 - val_loss: 0.3651 - val_categorical_accuracy: 0.8863\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.36654 to 0.36513, saving model to checkpoints/ResNet/weights_unfreezed_0.15-0.37.hdf5\n",
      "Epoch 16/20\n",
      "650/650 [==============================] - 585s 900ms/step - loss: 0.3551 - categorical_accuracy: 0.8907 - val_loss: 0.3731 - val_categorical_accuracy: 0.8839\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.36513\n",
      "Epoch 17/20\n",
      "650/650 [==============================] - 583s 897ms/step - loss: 0.3534 - categorical_accuracy: 0.8909 - val_loss: 0.3721 - val_categorical_accuracy: 0.8816\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36513\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 18/20\n",
      "650/650 [==============================] - 583s 897ms/step - loss: 0.3535 - categorical_accuracy: 0.8920 - val_loss: 0.3780 - val_categorical_accuracy: 0.8820\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36513\n",
      "Epoch 19/20\n",
      "650/650 [==============================] - 604s 929ms/step - loss: 0.3569 - categorical_accuracy: 0.8912 - val_loss: 0.3661 - val_categorical_accuracy: 0.8835\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36513\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "Epoch 20/20\n",
      "650/650 [==============================] - 597s 918ms/step - loss: 0.3384 - categorical_accuracy: 0.8980 - val_loss: 0.3684 - val_categorical_accuracy: 0.8816\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.36513\n",
      "\n",
      "Finetuning 4 hidden layers\n",
      "Epoch 1/10\n",
      "650/650 [==============================] - 596s 917ms/step - loss: 0.3445 - categorical_accuracy: 0.8939 - val_loss: 0.3674 - val_categorical_accuracy: 0.8843\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36744, saving model to checkpoints/ResNet/weights_unfreezed_4.01-0.37.hdf5\n",
      "Epoch 2/10\n",
      "650/650 [==============================] - 588s 904ms/step - loss: 0.3382 - categorical_accuracy: 0.8974 - val_loss: 0.3777 - val_categorical_accuracy: 0.8835\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36744\n",
      "Epoch 3/10\n",
      "650/650 [==============================] - 594s 914ms/step - loss: 0.3387 - categorical_accuracy: 0.8983 - val_loss: 0.3644 - val_categorical_accuracy: 0.8855\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36744 to 0.36435, saving model to checkpoints/ResNet/weights_unfreezed_4.03-0.36.hdf5\n",
      "Epoch 4/10\n",
      "650/650 [==============================] - 592s 911ms/step - loss: 0.3428 - categorical_accuracy: 0.8968 - val_loss: 0.3645 - val_categorical_accuracy: 0.8835\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36435\n",
      "Epoch 5/10\n",
      "650/650 [==============================] - 567s 872ms/step - loss: 0.3468 - categorical_accuracy: 0.8962 - val_loss: 0.3728 - val_categorical_accuracy: 0.8839\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36435\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "Epoch 6/10\n",
      "650/650 [==============================] - 587s 903ms/step - loss: 0.3475 - categorical_accuracy: 0.8931 - val_loss: 0.3645 - val_categorical_accuracy: 0.8905\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36435\n",
      "Epoch 7/10\n",
      "650/650 [==============================] - 748s 1s/step - loss: 0.3253 - categorical_accuracy: 0.8998 - val_loss: 0.3699 - val_categorical_accuracy: 0.8870\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36435\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "Epoch 8/10\n",
      "528/650 [=======================>......] - ETA: 1:22 - loss: 0.3399 - categorical_accuracy: 0.8923"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "lr_list = [0.0003, 0.0001, 0.0001, 0.0001, 0.0001]\n",
    "epoch_list = [20, 10, 10, 10, 10]\n",
    "for rnd in range(5):\n",
    "    n_layers = rnd * 4\n",
    "    if n_layers > 0:\n",
    "        for layer in base_model.layers[-n_layers:]:\n",
    "            layer.trainable = True\n",
    "    n_trainable = sum(m.trainable for m in base_model.layers)\n",
    "    print(f\"\\nFinetuning {n_trainable} hidden layers\")\n",
    "    \n",
    "    opt = SGD(lr=lr_list[rnd], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[categorical_accuracy])\n",
    "    \n",
    "    path = f\"checkpoints/ResNet/weights_unfreezed_{n_trainable}.\"\n",
    "    model_checkpointer = ModelCheckpoint(filepath=path+\"{epoch:02d}-{val_loss:.2f}.hdf5\", \n",
    "                                        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                  patience=2, min_lr=0.0000001, verbose=1)\n",
    "    early_stops = EarlyStopping(monitor='val_loss',\n",
    "                    patience=6, verbose=1,)\n",
    "    \n",
    "    my_callbacks = []\n",
    "    my_callbacks.append(model_checkpointer)\n",
    "    my_callbacks.append(reduce_lr)\n",
    "    my_callbacks.append(early_stops)\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=10412 // batch_size, # 10412\n",
    "            epochs=epoch_list[rnd],\n",
    "            verbose=1,\n",
    "            callbacks=my_callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=2588 // batch_size, # 2588\n",
    "            class_weight=CLASS_WEIGHTS,\n",
    "            )\n",
    "    pd.DataFrame(history.history).to_csv(f\"RESULTS/ResNet/history_unfreezed_{n_trainable}.csv\")\n",
    "    model.save(f'MODEL/ResNet/densenet_unfreezed_{n_trainable}.h5') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"meta-data/sample_submission.csv\")\n",
    "cols = list(df.columns)\n",
    "cols.remove(\"image_id\")\n",
    "pred_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "gen = pred_datagen.flow_from_directory(\n",
    "        'predict_data/',  # this is the target directory\n",
    "        target_size=(resol, resol),\n",
    "        batch_size=30,\n",
    "        class_mode=None,\n",
    "        shuffle=False) \n",
    "\n",
    "preds = model.predict_generator(gen, steps=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds, columns=cols)\n",
    "df[\"image_id\"] = gen.filenames\n",
    "df = df[[\"image_id\"] + cols]\n",
    "def f(x):\n",
    "    if x.startswith(\"predict/\"):\n",
    "        return x[8:]\n",
    "df[\"image_id\"] = df[\"image_id\"].apply(f)\n",
    "fnames = os.listdir(\"predict_data/predict/\")\n",
    "fnames = natsorted(fnames)\n",
    "df = df.set_index(\"image_id\")\n",
    "df = df.reindex(fnames)\n",
    "_ = df.hist(figsize=(20, 15), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"SUB/Sub8.csv\", index=True)\n",
    "model.save(\"SUB/Sub8_weights-ResNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
